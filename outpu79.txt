> /ros2_ws/build/h12_grasp_vlm/h12_grasp_vlm/move_arm_to_tracked_object.py(26)<module>()
-> from std_msgs.msg import Float64MultiArray
(Pdb) <h12_ros2_controller.core.robot_model.RobotModel object at 0x74a5254bebc0>
Tracking white can: custom_ros_messages.srv.UpdateTrackedObject_Response(result=True, message='Added track string: white can')
Tracking red can: custom_ros_messages.srv.UpdateTrackedObject_Response(result=True, message='Added track string: red can')
querries=[custom_ros_messages.srv.Query_Response(cloud=sensor_msgs.msg.PointCloud2(header=std_msgs.msg.Header(stamp=builtin_interfaces.msg.Time(sec=0, nanosec=0), frame_id=''), height=0, width=0, fields=[], is_bigendian=False, point_step=0, row_step=0, data=[], is_dense=False), prob=0.0, result=False, message='No tracked objects found for query: white can'), custom_ros_messages.srv.Query_Response(cloud=sensor_msgs.msg.PointCloud2(header=std_msgs.msg.Header(stamp=builtin_interfaces.msg.Time(sec=0, nanosec=0), frame_id=''), height=0, width=0, fields=[], is_bigendian=False, point_step=0, row_step=0, data=[], is_dense=False), prob=0.0, result=False, message='No tracked objects found for query: red can')]
Warning: Received empty PointCloud2 message.
Warning: Received empty PointCloud2 message.
Checking attributes
dir(i)=['HalfEdgeTriangleMesh', 'Image', 'LineSet', 'PointCloud', 'RGBDImage', 'TetraMesh', 'TriangleMesh', 'Type', 'Unspecified', 'VoxelGrid', '__add__', '__class__', '__copy__', '__deepcopy__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__iadd__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'clear', 'cluster_dbscan', 'colors', 'compute_convex_hull', 'compute_mahalanobis_distance', 'compute_mean_and_covariance', 'compute_nearest_neighbor_distance', 'compute_point_cloud_distance', 'covariances', 'create_from_depth_image', 'create_from_rgbd_image', 'crop', 'detect_planar_patches', 'dimension', 'estimate_covariances', 'estimate_normals', 'estimate_point_covariances', 'farthest_point_down_sample', 'get_axis_aligned_bounding_box', 'get_center', 'get_geometry_type', 'get_max_bound', 'get_min_bound', 'get_minimal_oriented_bounding_box', 'get_oriented_bounding_box', 'get_rotation_matrix_from_axis_angle', 'get_rotation_matrix_from_quaternion', 'get_rotation_matrix_from_xyz', 'get_rotation_matrix_from_xzy', 'get_rotation_matrix_from_yxz', 'get_rotation_matrix_from_yzx', 'get_rotation_matrix_from_zxy', 'get_rotation_matrix_from_zyx', 'has_colors', 'has_covariances', 'has_normals', 'has_points', 'hidden_point_removal', 'is_empty', 'normalize_normals', 'normals', 'orient_normals_consistent_tangent_plane', 'orient_normals_to_align_with_direction', 'orient_normals_towards_camera_location', 'paint_uniform_color', 'points', 'random_down_sample', 'remove_duplicated_points', 'remove_non_finite_points', 'remove_radius_outlier', 'remove_statistical_outlier', 'rotate', 'scale', 'segment_plane', 'select_by_index', 'transform', 'translate', 'uniform_down_sample', 'voxel_down_sample', 'voxel_down_sample_and_trace']
> /ros2_ws/build/h12_grasp_vlm/h12_grasp_vlm/move_arm_to_tracked_object.py(166)assign_multi_pcs_to_hands()
-> points = np.asarray(i.points)
(Pdb) k_points=array([], shape=(0, 3), dtype=float64)
Checking attributes
dir(i)=['HalfEdgeTriangleMesh', 'Image', 'LineSet', 'PointCloud', 'RGBDImage', 'TetraMesh', 'TriangleMesh', 'Type', 'Unspecified', 'VoxelGrid', '__add__', '__class__', '__copy__', '__deepcopy__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__iadd__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'clear', 'cluster_dbscan', 'colors', 'compute_convex_hull', 'compute_mahalanobis_distance', 'compute_mean_and_covariance', 'compute_nearest_neighbor_distance', 'compute_point_cloud_distance', 'covariances', 'create_from_depth_image', 'create_from_rgbd_image', 'crop', 'detect_planar_patches', 'dimension', 'estimate_covariances', 'estimate_normals', 'estimate_point_covariances', 'farthest_point_down_sample', 'get_axis_aligned_bounding_box', 'get_center', 'get_geometry_type', 'get_max_bound', 'get_min_bound', 'get_minimal_oriented_bounding_box', 'get_oriented_bounding_box', 'get_rotation_matrix_from_axis_angle', 'get_rotation_matrix_from_quaternion', 'get_rotation_matrix_from_xyz', 'get_rotation_matrix_from_xzy', 'get_rotation_matrix_from_yxz', 'get_rotation_matrix_from_yzx', 'get_rotation_matrix_from_zxy', 'get_rotation_matrix_from_zyx', 'has_colors', 'has_covariances', 'has_normals', 'has_points', 'hidden_point_removal', 'is_empty', 'normalize_normals', 'normals', 'orient_normals_consistent_tangent_plane', 'orient_normals_to_align_with_direction', 'orient_normals_towards_camera_location', 'paint_uniform_color', 'points', 'random_down_sample', 'remove_duplicated_points', 'remove_non_finite_points', 'remove_radius_outlier', 'remove_statistical_outlier', 'rotate', 'scale', 'segment_plane', 'select_by_index', 'transform', 'translate', 'uniform_down_sample', 'voxel_down_sample', 'voxel_down_sample_and_trace']
> /ros2_ws/build/h12_grasp_vlm/h12_grasp_vlm/move_arm_to_tracked_object.py(166)assign_multi_pcs_to_hands()
-> points = np.asarray(i.points)
(Pdb) k_points=array([], shape=(0, 3), dtype=float64)
[ros2run]: Process exited with failure 1
